{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "T2F_DCGAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbxXHorFtzwr"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaHHrrs5uApx"
      },
      "source": [
        "!unzip /content/drive/MyDrive/archive.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm0npMQXjtZ1"
      },
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/ryankiros/skip-thoughts.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kC3nwvOJiYND"
      },
      "source": [
        "!mkdir pretrained\n",
        "%cd pretrained\n",
        "!wget http://www.cs.toronto.edu/~rkiros/models/dictionary.txt\n",
        "!wget http://www.cs.toronto.edu/~rkiros/models/utable.npy\n",
        "!wget http://www.cs.toronto.edu/~rkiros/models/btable.npy\n",
        "!wget http://www.cs.toronto.edu/~rkiros/models/uni_skip.npz\n",
        "!wget http://www.cs.toronto.edu/~rkiros/models/uni_skip.npz.pkl\n",
        "!wget http://www.cs.toronto.edu/~rkiros/models/bi_skip.npz\n",
        "!wget http://www.cs.toronto.edu/~rkiros/models/bi_skip.npz.pkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UEDK4inRnPF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31c77269-1ae0-44ad-a8bb-e646ed90fd58"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from random import shuffle\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import img_to_array,load_img\n",
        "from PIL import Image\n",
        "import math\n",
        "import random\n",
        "from collections import Counter\n",
        "import nltk\n",
        "import json\n",
        "import h5py\n",
        "import pickle\n",
        "import re\n",
        "import urllib.request\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "import zipfile\n",
        "from keras.models import Model,Sequential\n",
        "from keras.layers import Input,Dense,Reshape,concatenate,Flatten,Lambda,LeakyReLU\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import UpSampling2D,Conv2D,MaxPooling2D,Conv2DTranspose\n",
        "from keras.optimizers import Adam\n",
        "from keras.initializers import TruncatedNormal,Zeros,RandomNormal,Constant\n",
        "from keras import backend as K\n",
        "import matplotlib.gridspec as gridspec\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "nltk.download('punkt')\n",
        "print(\"GPU:\",tf.test.gpu_device_name(),\"TF version:\",tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "GPU: /device:GPU:0 TF version: 2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyr85t1HkO8T"
      },
      "source": [
        "class DCGan(object):\n",
        "    model_name='dc_gan'\n",
        "\n",
        "    def __init__(self):\n",
        "        self.generator=None\n",
        "        self.discriminator=None\n",
        "        self.model=None\n",
        "        self.img_width=7\n",
        "        self.img_height=7\n",
        "        self.img_channels=1\n",
        "        self.text_input_dim=4800\n",
        "        self.random_input_dim=100\n",
        "        self.config=None\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_config_file_path(model_dir_path):\n",
        "        return os.path.join(model_dir_path,DCGan.model_name+'-config.npy')\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_weight_file_path(model_dir_path,model_type):\n",
        "        return os.path.join(model_dir_path,DCGan.model_name+'-'+model_type+'-weights.h5')\n",
        "    \n",
        "    def create_model(self):\n",
        "        init_img_width=4\n",
        "        init_img_height=4\n",
        "\n",
        "        random_input=Input((self.random_input_dim,))\n",
        "        text_input1=Input((self.text_input_dim,))\n",
        "        text_layer1=Dense(256,kernel_initializer=RandomNormal(stddev=0.02),bias_initializer=Constant(value=0))(text_input1)\n",
        "        text_layer1=LeakyReLU(alpha=0.2)(text_layer1)\n",
        "\n",
        "        merged=concatenate([random_input,text_layer1])\n",
        "        generator_layer=Activation('tanh')(merged)\n",
        "\n",
        "        generator_layer=Dense(512*init_img_width*init_img_height,kernel_initializer=RandomNormal(stddev=0.02),bias_initializer=Constant(value=0))(generator_layer)\n",
        "        generator_layer=BatchNormalization()(generator_layer)\n",
        "        generator_layer=LeakyReLU(alpha=0.2)(generator_layer)\n",
        "\n",
        "        generator_layer=Reshape((init_img_height,init_img_width,512),input_shape=(128*init_img_width*init_img_height,))(generator_layer)\n",
        "\n",
        "        generator_layer=Conv2DTranspose(256,kernel_size=5,strides=(2,2),padding='same',kernel_initializer=RandomNormal(stddev=0.02),bias_initializer=Constant(value=0))(generator_layer)\n",
        "        generator_layer=BatchNormalization()(generator_layer)\n",
        "        generator_layer=LeakyReLU(alpha=0.2)(generator_layer)\n",
        "\n",
        "        generator_layer=Conv2DTranspose(128,kernel_size=5,strides=(2,2),padding='same',kernel_initializer=RandomNormal(stddev=0.02),bias_initializer=Constant(value=0))(generator_layer)\n",
        "        generator_layer=BatchNormalization()(generator_layer)\n",
        "        generator_layer=LeakyReLU(alpha=0.2)(generator_layer)\n",
        "\n",
        "        generator_layer=Conv2DTranspose(64,kernel_size=5,strides=(2,2),padding='same',kernel_initializer=RandomNormal(stddev=0.02),bias_initializer=Constant(value=0))(generator_layer)\n",
        "        generator_layer=BatchNormalization()(generator_layer)\n",
        "        generator_layer=LeakyReLU(alpha=0.2)(generator_layer)\n",
        "\n",
        "        generator_layer=Conv2DTranspose(self.img_channels,kernel_size=5,strides=(2,2),padding='same',kernel_initializer=RandomNormal(stddev=0.02),bias_initializer=Constant(value=0))(generator_layer)\n",
        "        generator_layer=Activation('tanh')(generator_layer)\n",
        "\n",
        "        generator_layer=Lambda(lambda x:x/2.)(generator_layer)\n",
        "        generator_output=Lambda(lambda x:x+0.5)(generator_layer)\n",
        "\n",
        "        self.generator=Model([random_input,text_input1],generator_output, name='generator')\n",
        "        g_optim=Adam(lr=0.0002,beta_1=0.5)\n",
        "\n",
        "        self.generator.compile(loss='binary_crossentropy',optimizer=g_optim)\n",
        "        self.generator.summary()\n",
        "        print()\n",
        "\n",
        "        #discriminator\n",
        "        text_input2=Input((self.text_input_dim,))\n",
        "        text_layer2=Dense(256,kernel_initializer=RandomNormal(stddev=0.02),bias_initializer=Constant(value=0))(text_input2)\n",
        "\n",
        "        img_input2=Input((self.img_height,self.img_width,self.img_channels))\n",
        "\n",
        "        img_layer2=Conv2D(64,kernel_size=5,padding='same',strides=(2,2),kernel_initializer=TruncatedNormal(stddev=0.02),bias_initializer=Constant(value=0))(img_input2)\n",
        "        img_layer2=LeakyReLU(alpha=0.2)(img_layer2)\n",
        "\n",
        "        img_layer2=Conv2D(128,kernel_size=5,padding='same',strides=(2,2),kernel_initializer=TruncatedNormal(stddev=0.02),bias_initializer=Constant(value=0))(img_layer2)\n",
        "        img_layer2=BatchNormalization()(img_layer2)\n",
        "        img_layer2=LeakyReLU(alpha=0.2)(img_layer2)\n",
        "\n",
        "        img_layer2=Conv2D(256,kernel_size=5,padding='same',strides=(2,2),kernel_initializer=TruncatedNormal(stddev=0.02),bias_initializer=Constant(value=0))(img_layer2)\n",
        "        img_layer2=BatchNormalization()(img_layer2)\n",
        "        img_layer2=LeakyReLU(alpha=0.2)(img_layer2)\n",
        "        \n",
        "        img_layer2=Conv2D(512,kernel_size=5,padding='same',strides=(2,2),kernel_initializer=TruncatedNormal(stddev=0.02),bias_initializer=Constant(value=0))(img_layer2)\n",
        "        img_layer2=BatchNormalization()(img_layer2)\n",
        "        img_layer2=LeakyReLU(alpha=0.2)(img_layer2)\n",
        "\n",
        "        text_layer2=Lambda(K.expand_dims,arguments={'axis':1})(text_layer2)\n",
        "        text_layer2=Lambda(K.expand_dims,arguments={'axis':2})(text_layer2)\n",
        "        text_layer2=Lambda(K.tile,arguments={'n':(1,4,4,1)})(text_layer2)\n",
        "\n",
        "        img_layer2=concatenate([img_layer2,text_layer2],axis=3)\n",
        "        \n",
        "        img_layer2=Conv2D(512,kernel_size=5,padding='same',strides=(1,1),kernel_initializer=TruncatedNormal(stddev=0.02),bias_initializer=Constant(value=0))(img_layer2)\n",
        "        img_layer2=BatchNormalization()(img_layer2)\n",
        "        img_layer2=LeakyReLU(alpha=0.2)(img_layer2)\n",
        "\n",
        "        img_layer2=Flatten()(img_layer2)\n",
        "\n",
        "        discriminator_layer=Dense(1,kernel_initializer=RandomNormal(stddev=0.02),bias_initializer=Constant(value=0))(img_layer2)\n",
        "        discriminator_output=Activation('sigmoid')(discriminator_layer)\n",
        "\n",
        "        self.discriminator=Model([img_input2,text_input2],discriminator_output)\n",
        "        d_optim=Adam(learning_rate=0.0001,beta_1=0.5)\n",
        "        self.discriminator.compile(loss='binary_crossentropy',optimizer=d_optim)\n",
        "        self.discriminator.summary()\n",
        "\n",
        "        self.discriminator.trainable=False\n",
        "        model_output=self.discriminator([self.generator.output,text_input1])\n",
        "\n",
        "        self.model=Model([random_input,text_input1],model_output, name='discriminator')\n",
        "\n",
        "        self.model.compile(loss='binary_crossentropy',optimizer=g_optim)\n",
        "    \n",
        "    def load_batch(self,batch_idx,batch_size,image_label_pairs):\n",
        "        image_label_pair_batch=image_label_pairs[batch_idx*batch_size:(batch_idx+1)*batch_size]\n",
        "        image_files_batch=[]\n",
        "        wrong_image_batch=np.zeros((batch_size,self.img_height,self.img_width,self.img_channels))\n",
        "        real_image_batch=np.zeros((batch_size,self.img_height,self.img_width,self.img_channels))\n",
        "        noise=np.zeros((batch_size,self.random_input_dim))\n",
        "        skipthought_batch=np.zeros((batch_size,self.text_input_dim))\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            normalised_img=image_label_pair_batch[i][0]\n",
        "            real_image_batch[i,:,:,:]=normalised_img\n",
        "\n",
        "            idx=random.randint(0,len(image_label_pairs)-1)\n",
        "            wrong_img=image_label_pairs[idx][0]\n",
        "            wrong_image_batch[i,:,:,:]=wrong_img\n",
        "\n",
        "            skipthought_batch[i,:]=image_label_pair_batch[i][1]\n",
        "            noise[i,:]=np.random.uniform(-1,1,self.random_input_dim)\n",
        "            image_files_batch.append(image_label_pairs[i][2])\n",
        "        \n",
        "        return real_image_batch,wrong_image_batch,noise,skipthought_batch,image_files_batch\n",
        "        \n",
        "    def fit(self,model_dir_path,image_label_pairs,epochs=None,batch_size=None,snapshot_dir_path=None):\n",
        "        if epochs is None:\n",
        "            epochs=100\n",
        "        \n",
        "        if batch_size is None:\n",
        "            batch_size=128\n",
        "        \n",
        "        self.config=dict()\n",
        "        self.config['img_width']=self.img_width\n",
        "        self.config['img_height']=self.img_height\n",
        "        self.config['random_input_dim']=self.random_input_dim\n",
        "        self.config['text_input_dim']=self.text_input_dim\n",
        "        self.config['img_channels']=self.img_channels\n",
        "\n",
        "        config_file_path=DCGan.get_config_file_path(model_dir_path)\n",
        "\n",
        "        np.save(config_file_path,self.config)\n",
        "\n",
        "        n_batches=image_label_pairs.shape[0]//batch_size\n",
        "        d_loss_list=[]\n",
        "        g_loss_list=[]\n",
        "        for epoch in range(epochs):\n",
        "            epoch_d_loss=0\n",
        "            epoch_g_loss=0\n",
        "            start=time.time()\n",
        "            for batch_idx in range(n_batches):\n",
        "                real_images_batch,wrong_images_batch,noise,skipthought_batch,image_files_batch=self.load_batch(batch_idx,batch_size,image_label_pairs)\n",
        "\n",
        "                fake_images_batch=self.generator.predict([noise,skipthought_batch],verbose=0)\n",
        "\n",
        "                self.discriminator.trainable=True\n",
        "                if (batch_idx+1)%4==0:\n",
        "                    d_loss1=self.discriminator.train_on_batch([fake_images_batch,skipthought_batch],np.array([1]*batch_size))\n",
        "                    d_loss2=self.discriminator.train_on_batch([wrong_images_batch,skipthought_batch],np.array([0]*batch_size))\n",
        "                    d_loss3=self.discriminator.train_on_batch([fake_images_batch,skipthought_batch],np.array([0]*batch_size))\n",
        "                \n",
        "                else:\n",
        "                    d_loss1=self.discriminator.train_on_batch([real_images_batch,skipthought_batch],np.array([1]*batch_size))\n",
        "                    d_loss2=self.discriminator.train_on_batch([wrong_images_batch,skipthought_batch],np.array([0]*batch_size))\n",
        "                    d_loss3=self.discriminator.train_on_batch([fake_images_batch,skipthought_batch],np.array([0]*batch_size))\n",
        "                self.discriminator.trainable=False\n",
        "\n",
        "                d_loss=d_loss1+0.5*(d_loss2+d_loss3)\n",
        "                \n",
        "                g_loss=self.model.train_on_batch([noise,skipthought_batch],np.array([1]*batch_size))\n",
        "\n",
        "                epoch_d_loss+=d_loss\n",
        "                epoch_g_loss+=g_loss\n",
        "\n",
        "                if (batch_idx+1)%100==0 and snapshot_dir_path is not None:\n",
        "                    generated_images=self.generator.predict([noise,skipthought_batch],verbose=0)\n",
        "                    self.save_snapshots(generated_images,snapshot_dir_path=snapshot_dir_path,epoch=epoch,batch_idx=batch_idx)\n",
        "\n",
        "            d_loss_list.append(epoch_d_loss/n_batches)\n",
        "            g_loss_list.append(epoch_g_loss/n_batches)\n",
        "            print('Epoch: '+str(epoch+1)+'/'+str(epochs)+' epoch_duration: '+str(time.time()-start)+' discriminator_loss: '+str(epoch_d_loss/n_batches)+' generator_loss: '+str(epoch_g_loss/n_batches))\n",
        "            if (epoch+1)%5==0 or (epoch+1)==epochs:\n",
        "                self.generator.save_weights(DCGan.get_weight_file_path(model_dir_path,'generator'),True)\n",
        "                self.discriminator.save_weights(DCGan.get_weight_file_path(model_dir_path,'discriminator'),True)\n",
        "                with h5py.File('losses_list.h5','w') as out:\n",
        "                    out.create_dataset(\"discriminator\",data=np.array(d_loss_list))\n",
        "                    out.create_dataset(\"generator\",data=np.array(g_loss_list))\n",
        "    \n",
        "    def generate_image_from_text(self,caption,skipthought_model):\n",
        "        encoded_text=skipthoughts.encode(skipthought_model,caption)\n",
        "        noise=np.random.uniform(-1,1,self.random_input_dim)\n",
        "        noise=np.expand_dims(noise,axis=0)\n",
        "        generated_image=self.generator.predict([noise,encoded_text],verbose=0)\n",
        "        print('Caption: '+caption[0])\n",
        "        plt.imshow(generated_image[0])\n",
        "\n",
        "    def save_snapshots(self,generated_images,snapshot_dir_path,epoch,batch_idx):\n",
        "        plot_batch(generated_images,DCGan.model_name,epoch,batch_idx,snapshot_dir_path)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYJ66QJqT7Qt"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def plot_batch(generated_images,model_name,epoch,batch_idx,snapshot_dir_path):\n",
        "    fig=plt.figure(1)\n",
        "    grid=ImageGrid(fig,111,nrows_ncols=(2,8),axes_pad=0.05)\n",
        "    size=2*8\n",
        "    for i in range(size):\n",
        "        grid[i].axis('off')\n",
        "        grid[i].imshow((generated_images[i]*255).astype(np.uint8))\n",
        "    plt.savefig(os.path.join(snapshot_dir_path,model_name+'-'+str(epoch)+'-'+str(batch_idx)+'.png'))\n",
        "\n",
        "def img_from_normalised_img(normalised_img):\n",
        "    image=normalised_img.astype(float)*255\n",
        "    image=image.astype('uint8')\n",
        "    return image\n",
        "\n",
        "def load_normalised_img_and_cap(img_path, caption_file):\n",
        "    IMAGES_COUNT = 50000\n",
        "    imgs = []\n",
        "    names = []\n",
        "    for pic_file in tqdm(os.listdir(img_path)[:IMAGES_COUNT]):\n",
        "      pic = Image.open(img_path + pic_file).resize((img_width, img_height))\n",
        "      pic.thumbnail((img_width, img_height), Image.ANTIALIAS)\n",
        "      imgs.append(np.uint8(pic))\n",
        "      names.append(pic_file)\n",
        "    caps = {}\n",
        "    with open(caption_file,'r') as c:\n",
        "        for line in c.readlines():\n",
        "            img_name = line.strip().split('\\t')[0]\n",
        "            cap = \" \".join(line.split('\\t')[1].split('|'))\n",
        "            if cap == \"\" or cap == \" \":\n",
        "                cap = \"This is a person with a face and nothing else.\"\n",
        "            caps[img_name] = cap\n",
        "    # with open(caption_file, 'r') as c:\n",
        "    #     for line in c.readlines()[1:]:\n",
        "    #         img_name = line.strip().split(' ')[0]\n",
        "    #         cap = np.array(line.strip().split(' ')[1:])\n",
        "    #         caps[img_name] = cap\n",
        "    # print(caps['000001.jpg'].shape)\n",
        "    captions=[]\n",
        "    for i in range(len(names)):\n",
        "        captions.append(caps.setdefault(names[i], \"This is a person with a face and nothing else.\"))\n",
        "    vectors = captions\n",
        "    if not os.path.exists('/content/drive/MyDrive/text2face_gan/skipthought_vectors_50k.pkl'):\n",
        "        model=skipthoughts.load_model()\n",
        "        vectors=skipthoughts.encode(model,captions)\n",
        "        with open('/content/drive/MyDrive/text2face_gan/skipthought_vectors.pkl','wb') as f:\n",
        "            pickle.dump(vectors,f)\n",
        "    else:\n",
        "        with open('/content/drive/MyDrive/text2face_gan/skipthought_vectors_50k.pkl','rb') as f:\n",
        "            vectors=pickle.load(f)\n",
        "\n",
        "    result=[]\n",
        "    for i in range(len(imgs)):\n",
        "        result.append([imgs[i],vectors[i],names[i]])\n",
        "    \n",
        "    return np.array(result)\n",
        "\n",
        "def resize(img,input_shape):\n",
        "  height,width=input_shape\n",
        "  return cv2.resize(img,(width,height))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtNdhXMKkU9A"
      },
      "source": [
        "img_width=80\n",
        "img_height=96\n",
        "img_channels=3\n",
        "\n",
        "WIDTH = 80\n",
        "HEIGHT = 96"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-oKD9WHT0lk",
        "outputId": "dd4f26ce-2a1b-4452-90d8-da70595758a4"
      },
      "source": [
        "%cd /content/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9vu9pRzk1O2",
        "outputId": "b99e7d8c-55d7-47b8-f8f7-21392c10c295"
      },
      "source": [
        "import skipthoughts\n",
        "\n",
        "seed=2020\n",
        "np.random.seed(seed)\n",
        "model_dir_path='models'\n",
        "img_path='/content/img_align_celeba/img_align_celeba/'\n",
        "caption_file = '/content/caps.txt'\n",
        "image_label_pairs=load_normalised_img_and_cap(img_path, caption_file)\n",
        "shuffle(image_label_pairs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 50000/50000 [01:40<00:00, 495.39it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ey6_iFlMorFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f6147a3-68d1-4cad-a261-865c95cea914"
      },
      "source": [
        "dcgan=DCGan()\n",
        "dcgan.img_width=64\n",
        "dcgan.img_height=64\n",
        "dcgan.img_channels=3\n",
        "dcgan.random_input_dim=100\n",
        "dcgan.text_input_dim=4800\n",
        "batch_size=64\n",
        "epochs=200\n",
        "dcgan.create_model()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"generator\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 4800)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 256)          1229056     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_1 (InputLayer)            [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)         (None, 256)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 356)          0           input_1[0][0]                    \n",
            "                                                                 leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 356)          0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 8192)         2924544     activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 8192)         32768       dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 8192)         0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 4, 4, 512)    0           leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 8, 8, 256)    3277056     reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 8, 8, 256)    1024        conv2d_transpose[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 8, 8, 256)    0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 16, 16, 128)  819328      leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 16, 16, 128)  512         conv2d_transpose_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 16, 16, 128)  0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 32, 32, 64)   204864      leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 64)   256         conv2d_transpose_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 32, 32, 64)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 64, 64, 3)    4803        leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 64, 64, 3)    0           conv2d_transpose_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 64, 64, 3)    0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 64, 64, 3)    0           lambda[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 8,494,211\n",
            "Trainable params: 8,476,931\n",
            "Non-trainable params: 17,280\n",
            "__________________________________________________________________________________________________\n",
            "\n",
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 64, 64, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 64)   4864        input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 32, 32, 64)   0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 16, 16, 128)  204928      leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 16, 16, 128)  512         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, 16, 16, 128)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 8, 8, 256)    819456      leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 8, 8, 256)    1024        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 4800)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)       (None, 8, 8, 256)    0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 256)          1229056     input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 4, 4, 512)    3277312     leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 1, 256)       0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 4, 4, 512)    2048        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, 1, 1, 256)    0           lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)       (None, 4, 4, 512)    0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4 (Lambda)               (None, 4, 4, 256)    0           lambda_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 4, 4, 768)    0           leaky_re_lu_8[0][0]              \n",
            "                                                                 lambda_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 4, 4, 512)    9830912     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 4, 4, 512)    2048        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)       (None, 4, 4, 512)    0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 8192)         0           leaky_re_lu_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            8193        flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 1)            0           dense_3[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 15,380,353\n",
            "Trainable params: 15,377,537\n",
            "Non-trainable params: 2,816\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q594hRumpIVJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bc462d5-6435-48dd-eb4e-ecf5a5aa9572"
      },
      "source": [
        "with tf.device('/gpu:0'):\n",
        "  dcgan.fit(model_dir_path=model_dir_path,\n",
        "            image_label_pairs=image_label_pairs,\n",
        "            snapshot_dir_path='snapshots',\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/200 epoch_duration: 339.9365015029907 discriminator_loss: 1.862405559541741 generator_loss: 0.8810346476094518\n",
            "Epoch: 2/200 epoch_duration: 356.5037784576416 discriminator_loss: 1.6974921808715209 generator_loss: 0.9056111268136321\n",
            "Epoch: 3/200 epoch_duration: 375.8615710735321 discriminator_loss: 1.6480528653316706 generator_loss: 0.9252977371979004\n",
            "Epoch: 4/200 epoch_duration: 395.00529885292053 discriminator_loss: 1.6176933720707893 generator_loss: 0.9273769383851759\n",
            "Epoch: 5/200 epoch_duration: 418.76893377304077 discriminator_loss: 1.5996374668274433 generator_loss: 0.9202556036956484\n",
            "Epoch: 6/200 epoch_duration: 450.0394198894501 discriminator_loss: 1.587459905428404 generator_loss: 0.9210686414250949\n",
            "Epoch: 7/200 epoch_duration: 482.3057882785797 discriminator_loss: 1.5788968922367628 generator_loss: 0.9236420818846601\n",
            "Epoch: 8/200 epoch_duration: 509.61283898353577 discriminator_loss: 1.5730991708389013 generator_loss: 0.9382573537118304\n",
            "Epoch: 9/200 epoch_duration: 542.9269020557404 discriminator_loss: 1.564836685353754 generator_loss: 0.9458561937268657\n",
            "Epoch: 10/200 epoch_duration: 588.8446824550629 discriminator_loss: 1.5486293677407557 generator_loss: 0.9465918854623079\n",
            "Epoch: 11/200 epoch_duration: 623.7718031406403 discriminator_loss: 1.5420388841045194 generator_loss: 0.9408876527286828\n",
            "Epoch: 12/200 epoch_duration: 668.5723094940186 discriminator_loss: 1.551202391690447 generator_loss: 0.9655332214243129\n",
            "Epoch: 13/200 epoch_duration: 716.7699408531189 discriminator_loss: 1.5291762756286296 generator_loss: 0.9480759511378603\n",
            "Epoch: 14/200 epoch_duration: 784.7707779407501 discriminator_loss: 1.5223025190673778 generator_loss: 0.9428757410043332\n",
            "Epoch: 15/200 epoch_duration: 850.484441280365 discriminator_loss: 1.5258719809257955 generator_loss: 0.9611687239703082\n",
            "Epoch: 16/200 epoch_duration: 944.770304441452 discriminator_loss: 1.5197968931436996 generator_loss: 0.9589054473841542\n",
            "Epoch: 17/200 epoch_duration: 978.6547348499298 discriminator_loss: 1.5061126730849588 generator_loss: 0.9634698675170292\n",
            "Epoch: 18/200 epoch_duration: 1022.1740050315857 discriminator_loss: 1.503934422934788 generator_loss: 0.9367978002747256\n",
            "Epoch: 19/200 epoch_duration: 1094.5546174049377 discriminator_loss: 1.5083041979994496 generator_loss: 0.9477679210496773\n",
            "Epoch: 20/200 epoch_duration: 1189.1016955375671 discriminator_loss: 1.510231633135207 generator_loss: 0.9553368556362108\n",
            "Epoch: 21/200 epoch_duration: 1272.1384184360504 discriminator_loss: 1.4870182895000246 generator_loss: 0.9413117612217209\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9SuBTsPzt7p"
      },
      "source": [
        "dcgan.generator.load_weights(model_dir_path+'/dc_gan-generator-weights.h5')\n",
        "skipthought_model=skipthoughts.load_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUCzfedQzuz4"
      },
      "source": [
        "caption=['The woman has oval face. She has straight hair which is brown in colour. The smiling, young attractive woman has heavy makeup. She’s wearing lipstick.']\n",
        "dcgan.generate_image_from_text(caption,skipthought_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qJnMG8Q1voi"
      },
      "source": [
        "!rm -r snap*"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}